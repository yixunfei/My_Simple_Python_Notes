
## Python的多进程

`multiprocessing`模块是Python标准库的一部分，用于创建和管理进程。它提供了一种简单而高效的方式来利用多核处理器的能力，通过在多个进程中同时执行任务，可以加快程序的执行速度和提高系统的吞吐量。与多线程相比，多进程可以绕过全局解释器锁（GIL）的限制，从而在多核CPU上实现真正的并行计算。

### `multiprocessing` 模块的主要组件

#### `Process`类

`Process`类是`multiprocessing`模块的一部分，**用于创建和管理子进程**。`Process`类提供了一个简单的方式来自定义一个进程的行为，包括指定要执行的目标函数、进程名称、参数等。

**`Process`类的基本用法**

`Process`类的构造函数接受以下参数：
- `group`: 通常为`None`，因为Python的进程模型不支持组。
- `target`: 可调用对象，指定进程将执行的函数。
- `name`: 字符串，指定进程的名字。
- `args`: 目标函数的位置参数，作为元组传递。
- `kwargs`: 目标函数的关键字参数，作为字典传递。

```python
from multiprocessing import Process

def worker(name):
    print(f'Hello from {name}!')

if __name__ == '__main__':
    # 创建一个进程
    p = Process(target=worker, args=('Subprocess',))
    # 启动进程
    p.start()
    # 等待进程结束
    p.join()
    print('Main process finished.')
```


**进程的生命周期**

- `start()`: 调用此方法会启动进程，执行`target`函数。
- `join([timeout])`: 调用此方法会阻塞主进程，直到子进程结束，或者超时（如果提供了`timeout`参数）。
- `is_alive()`: 返回`True`如果进程正在运行，否则返回`False`


**进程的属性**

- `pid`: 进程的ID，只有在调用`start()`之后才有值。
- `name`: 进程的名称，可以通过构造函数设置或之后修改。
```python
from multiprocessing import Process

def worker(index):
    print(f'Worker {index} started.')

if __name__ == '__main__':
    processes = []
    for i in range(5):
        p = Process(target=worker, args=(i,))
        processes.append(p)
        p.start()
        
    for p in processes:
        p.join()
        
    print('All workers finished.')

```

**注意事项**

- **进程间通信**: 需要使用`multiprocessing`模块提供的队列、管道等工具。
- 进程的创建和销毁比线程要昂贵，因此频繁创建和销毁进程可能会影响性能。
- **进程隔离**：每个进程都有自己的内存空间，因此在进程间传递对象需要序列化和反序列化，这可能会带来额外的开销。
- **主进程与子进程**：在if __name__ == '__main__':下启动进程可以防止子进程再次启动更多的子进程，避免无限递归。
- **异常处理**：子进程中的异常不会直接在主进程中抛出，需要通过队列或管道返回异常信息。
- **资源管理**：进程创建和销毁的开销比线程高，因此频繁创建和销毁进程可能会影响性能。

#### `Pool`类

在Python的`multiprocessing`模块中，`Pool`类是一个非常强大的工具，用于并行执行函数。`Pool`对象实质上是一个进程池，它能够管理一组工作进程，这些进程可以并行地执行任务，而无需每次执行任务时创建和销毁进程，这样可以减少开销，提高效率。

**Pool类的基本用法**

- `apply(func, args=None, kwds=None)`: 异步执行单个任务，等待其完成并返回结果。如果`args`和`kwds`未指定，则`func`应该是无参数的。
- `apply_async(func, args=None, kwds=None, callback=None, error_callback=None)`: 异步执行单个任务，不等待其完成，可以指定回调函数`callback`和错误回调函数`error_callback`。
- `map(function, iterable, chunksize=None)`: 并行地将`function`应用于`iterable`中的每个项，返回一个结果列表。
- `imap(function, iterable, chunksize=1)`: 类似于`map`，但返回一个迭代器，可以逐个获取结果。
- `imap_unordered(function, iterable, chunksize=1)`: 与`imap`类似，但是结果可能无序。


**注意事项**

- Pool对象是一个上下文管理器，使用`with`语句可以自动关闭进程池和清理资源。
- 进程池中的进程是无共享的，每个进程都有自己的内存空间，**因此在进程间传递对象需要序列化和反序列化，带来额外的开销**。
- Pool中的进程是不可重用的，一旦进程池关闭，就不能再添加新的任务。
- 使用Pool时，确保在`if __name__ == '__main__'`块内启动进程，以防止子进程无限递归启动更多进程。

```python
import math  
from multiprocessing import Pool  
  
def calculate_sqrt(number):  
    """ 计算给定数字的平方根 """    return math.sqrt(number)  
  
if __name__ == '__main__':  
    numbers = [x * x for x in range(1, 11)]  # 生成一系列的平方数  
    with Pool(processes=4) as pool:  # 创建一个包含4个进程的进程池  
        results = pool.map(calculate_sqrt, numbers)  # 使用map方法并行计算平方根  
        print("Square roots:", results)
```


#### `multiprocessing.Queue`类

在Python的`multiprocessing`模块中，`Queue`类提供了一种**进程安全的队列实现，用于在多个进程之间安全地传递数据**。`multiprocessing.Queue`不同于`queue.Queue`，后者主要用于线程间的通信，而`multiprocessing.Queue`则专为进程间通信设计。

`multiprocessing.Queue`的构造函数可以接受一个可选的`maxsize`参数，用于指定队列的最大长度。如果不指定`maxsize`，则队列**默认为无限大小**。

**常用方法**：

- `put(item)`: 将 item放入队列。如果队列已满（并且设置了`maxsize`），则调用进程将被阻塞，直到队列中有空间。
- `get(block=True, timeout=None):` 从队列中取出一个项目。如果`block`为`True`且`timeout`为`None`，则调用将阻塞直到有项目可用。如果`timeout`是非负数，则调用将阻塞最多`timeou`t秒，然后**抛出`queue.Empty`异常**。
- `qsize()`: 返回队列的当前大小。注意，由于队列可能在调用qsize()后立即改变，因此这个方法的结果可能不是实时准确的。
- `empty()`: 如果队列为空，返回`True`，否则返回`False`。
- `full()`: 如果队列已满（并且设置了`maxsize`），返回`True`，否则返回`False`。

```python
from multiprocessing import Process, Queue

def write_to_queue(q):
    q.put('Hello from the child process!')

def read_from_queue(q):
    print(q.get())

if __name__ == '__main__':
    queue = Queue()  # 创建一个队列

    # 创建并启动写入进程
    writer_process = Process(target=write_to_queue, args=(queue,))
    writer_process.start()

    # 创建并启动读取进程
    reader_process = Process(target=read_from_queue, args=(queue,))
    reader_process.start()

    # 等待两个进程完成
    writer_process.join()
    reader_process.join()

```

#### Pipe类

在Python的`multiprocessing`模块中，**`Pipe`是一个用于进程间通信的工具，它创建了一对连接的管道，允许数据在两个进程之间双向传输**。`Pipe`对象由`multiprocessing.Pipe()`函数创建，返回两个连接对象，代表管道的两端。


`multiprocessing.Pipe`函数可以接受一个布尔参数`duplex`，默认为`True`。如果`duplex`为`True`，那么创建的管道是全双工的，即管道的每一端都可以发送和接收数据。如果`duplex`为`False`，那么管道的一端只能发送数据，另一端只能接收数据


**基本用法**

```python
from multiprocessing import Process, Pipe

def sender(conn):
    conn.send('Hello from child process!')
    conn.close()

if __name__ == '__main__':
    parent_conn, child_conn = Pipe()  # 创建管道

    # 创建并启动子进程
    p = Process(target=sender, args=(child_conn,))
    p.start()

    # 从管道接收数据
    print(parent_conn.recv())  # 输出：Hello from child process!

    # 等待子进程结束
    p.join()
```

**注意事项**

- 管道是进程安全的，可以被多个进程同时访问，但通常一个管道的两端分别由不同的进程持有。
- **管道中的数据传输是阻塞的**，即发送方必须等待接收方接收数据后才能继续发送下一个数据。
- 由于数据需要在进程间传递，因此通过管道发送的项目**必须是可序列化的**，这样才能在进程间正确传输。


#### 进程Semaphore

Python的`multiprocessing`模块提供了一个`Semaphore`类，可以用来实现进程间的同步。

使用`multiprocessing.Semaphore()`创建一个信号量对象，可以指定信号量的初始值。

使用基本与下面的线程信号量相同，见线程部分。


## Python中的多线程

注：python多线程拿来做做异步IO即可，计算密集型的还是得用多进程。

Python提供了两个模块来处理线程：
- `thread`：这是Python的标准库中较低级别的模块，直接封装了C语言的线程库，但它的功能相对有限。
- `threading`：这是一个更高级的模块，提供了更丰富的线程管理功能，如锁、信号量、条件变量等，通常推荐使用threading模块。

使用操作系统级别的线程，可以利用多核处理器的并行计算能力，但受制于Python的`GIL`（全局解释器锁），在CPU密集型任务上可能不会显著提高性能。

## 线程创建与使用

**线程创建通常使用`threading`模块，用于创建和管理线程**。使用`threading.Thread`可以轻松地在Python程序中实现多线程，从而让程序能够并发执行多个任务。
### 基本用法

####  直接使用Thread类
创建 `threading.Thread` 实例时，通常需要指定线程要执行的目标函数（`target`）以及该函数的参数（`args`）。一旦线程创建完毕，可以调用其`start()`方法来启动线程，线程会开始执行`target`函数。

**参数说明**
- `target`：可调用对象，表示线程运行时要执行的函数。
- `args`：目标函数的位置参数，以元组的形式传递。
- `kwargs`：目标函数的关键字参数，以字典形式传递。
- `daemon`：布尔值，如果设置为 `True`，则表示这是一个守护线程，守护线程会在所有非守护线程结束后自动终止。

**方法说明**
- `start()`: 开始执行线程。
- `join([timeout])`: 阻塞当前线程，直到调用该方法的线程完成或超时。如果不传入`timeout`参数，将一直阻塞直到线程结束。
- `is_alive()`: 返回线程是否仍在运行的布尔值。

```python
import threading
import time

def my_function(id):
    print(f"Thread {id} started")
    time.sleep(2)  # 模拟耗时操作
    print(f"Thread {id} finished")

# 创建线程
thread = threading.Thread(target=my_function, args=(1,))

# 启动线程
thread.start()

# 等待线程结束
thread.join()

print("Main thread finished.")
```

#### 继承Thread类

除了直接使用`threading.Thread`，你还可以通过继承`threading.Thread`来创建自己的线程类，并重写`run()`方法来定义线程的行为。这种方式使得线程的管理和控制更加灵活。

```python
import threading
import time

class MyThread(threading.Thread):
    def __init__(self, id):
        threading.Thread.__init__(self)
        self.id = id

    def run(self):
        print(f"Thread {self.id} started")
        time.sleep(2)
        print(f"Thread {self.id} finished")

# 创建并启动线程
thread = MyThread(1)
thread.start()
thread.join()

print("Main thread finished.")
```


#### 线程池

在Python中，线程池是通过`concurrent.futures`模块中的`ThreadPoolExecutor`类来实现的。线程池提供了一种有效管理线程的方法，它预先创建一定数量的线程，然后将任务分配给这些线程执行，而无需为每个任务单独创建和销毁线程，从而减少了线程创建和销毁的开销。

`ThreadPoolExecutor`类的构造函数可以接受`max_workers`参数，用于指定线程池中线程的最大数量。如果没有指定，**它将默认为机器的处理器核心数乘以5**。

**常用方法：**

- **提交任务**：使用`submit`方法将任务提交给线程池。`submit`方法接受一个可调用对象和任意数量的位置和关键字参数，这些参数将被传递给该可调用对象。`submit`方法会返回一个`Future`对象，你可以使用这个对象来查询任务的状态或获取任务的结果。
- **获取任务结果**：使用`Future`对象的`result()`方法来获取任务的结果。如果任务尚未完成，`result()`方法将阻塞，直到任务完成。
- **关闭线程池**：当不再需要线程池时，应该调用`shutdown()`方法来关闭线程池。`shutdown()`方法可以接受一个`wait`参数，如果设为`True`（默认），则会等待所有任务完成后再关闭线程池。

```python
import concurrent.futures
import time

def long_running_task(n):
    time.sleep(n)
    return n * n

if __name__ == "__main__":
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        # 提交多个任务
        futures = [executor.submit(long_running_task, i) for i in range(5)]
        
        # 收集结果
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            print(f"Task returns: {result}")
```

**注意事项**

- 线程池中的线程是有限的，如果任务数量超过线程池的最大线程数，额外的任务将在队列中等待，直到线程池中有空闲线程。
- 使用`ThreadPoolExecutor`可以提高I/O密集型任务的效率，但对于CPU密集型任务，多进程可能更为合适，因为线程会受到全局解释器锁（GIL）的影响。
- 在使用线程池时，确保在`if __name__ == "__main__":`块中启动线程，以避免在导入模块时意外地启动线程。

## 线程安全

### 内存同步-锁

#### 互斥锁 Lock

当一个线程获得了锁，其他试图获得相同锁的线程将被阻塞（包括该线程自身，即**不可重入**），直到锁被释放。

```python
import threading  
import time  
  
# 创建锁  
lock = threading.Lock()  
def worker():  
    getLock = lock.acquire(blocking=True,timeout=2)  
    if getLock:  
        print('get lock')  
    else:  
        print('get lock fail timeout!')  
        return  
    try:  
        print('running...')  
        time.sleep(10000)  
        pass  
    finally:  
        lock.release()  
  
t1 = threading.Thread(target=worker)  
t2 = threading.Thread(target=worker)  
t1.start()  
t2.start()  
t1.join()  
t2.join()  
print('end')
```

**锁的获取**

**`lock.acquire()`用于尝试获取锁**。当一个线程调用`lock.acquire()`时，它试图获取锁的所有权。如果锁当前未被任何线程持有，那么调用线程将获得锁并可以继续执行。如果锁已经被另一个线程持有，那么调用线程将被阻塞，直到锁被释放或超时。

`lock.acquire([blocking[, timeout]])`：

- `blocking`：布尔值，默认为True。如果True，则调用线程将被阻塞直到锁可用；如果False，则调用线程不会被阻塞，而是立即返回False（如果锁不可用）或True（如果锁可用并被获取）。
- `timeout`：浮点数，仅当`blocking`为`True`时有效。它指定了**等待锁的最大时间**（以秒为单位）。如果在指定时间内锁仍未可用，`acquire()`将返回`False`。

**锁的释放**

`lock.release()`来释放锁，以避免死锁。通常，建议使用`with`语句来自动管理锁的获取和释放（如果线程在持有锁期间抛出了异常，而没有正确释放锁，那么锁将保持锁定状态，这可能导致其他线程永远无法获取锁。使用`with`语句可以确保即使在异常情况下锁也能被正确释放）：
```python
  with lock:
      # 临界区代码
```

在多线程环境中，不当的锁使用可能会导致性能下降，因为线程可能花费大量时间等待锁。因此，在设计多线程应用时，需要对关键且正确的临界资源进行加锁同步。


#### RLock（重入锁）

`threading.RLock()` 是一种重入锁，提供允许当前已经获取到锁的线程，在自身持有释放相同锁之前。可以直接获取而不需要额外等待,即重新进入临界代码块的特性。其他用法与`Lock`相同。
```python
import threading  
import time  
  
# 创建RLock
lock = threading.RLock()  
def worker():  
    with lock:  
        print('初次 locked 01')  
        with lock:  
            print('重入 locked 02')  
        print('running...')  
        time.sleep(3)  
        pass  
  
t1 = threading.Thread(target=worker)  
t1.start()  
t1.join()  
print('end')
```


#### Condition（条件变量）

`threading.Condition`是Python标准库`threading`模块中提供的一个类，用于实现线程间的高级同步。它结合了锁的功能和等待队列的能力，允许一个或多个线程调用 wait() 方法阻塞等待某些条件成立,，然后由另一个线程调用 `notify()` 或 `notify_all()` 方法唤醒通知这些条件已经满足。

**主要方法:**
**`__init__(lock=None)`**:
- 创建一个新的`Condition`对象。`lock`参数可以是一个锁对象（如`threading.Lock`或`threading.RLock`），如果不提供，则会创建一个新的`RLock`。
**`acquire([blocking[, timeout]])`**:
- 获取底层锁。与`Lock`和`RLock`的`acquire`方法类似。
**`release()`**
- 释放底层锁。与`Lock`和`RLock`的`release`方法类似。
**`wait([timeout])`**
- 释放底层锁并进入等待状态，直到被`notify()`或`notify_all()`唤醒。如果提供了`timeout`参数，等待最多持续`timeout`秒，之后线程将继续执行。
**`wait_for(predicate, [timeout])`**
- 类似于`wait`，但等待直到`predicate`函数返回`True`。`predicate`应该是无参数的函数或方法。
**`notify(n=1)`**
- 唤醒n个等待的线程（如果有的话）。如果n大于等待队列中的线程数，则所有等待线程都将被唤醒。
**`notify_all()`**
- 唤醒所有等待的线程。

```python
import threading  
  
buffer = []  
buffer_size = 10  
condition = threading.Condition()  
  
def producer():  
    global buffer  
    for i in range(20):  
        with condition:  
            while len(buffer) == buffer_size:  
                condition.wait()  # 缓冲区满，等待  
            buffer.append(i)  
            print(f"Produced {i}, buffer size: {len(buffer)}")  
            condition.notify()  # 通知消费者缓冲区有新元素  
  
def consumer():  
    global buffer  
    for _ in range(20):  
        with condition:  
            while len(buffer) == 0:  
                condition.wait()  # 缓冲区空，等待  
            item = buffer.pop(0)  
            print(f"Consumed {item}, buffer size: {len(buffer)}")  
            condition.notify()  # 通知生产者缓冲区有空间  
  
producer_thread = threading.Thread(target=producer)  
consumer_thread = threading.Thread(target=consumer)  
  
producer_thread.start()  
consumer_thread.start()  
  
producer_thread.join()  
consumer_thread.join()
```


#### 线程Semaphore（信号量）

`threading.Semaphore()` 控制同时访问某个资源的线程数量。信号量维护了一个计数器，每当调用 `acquire()` 方法时计数器减1，当计数器为0时，后续的 `acquire()` 调用将阻塞，直到有线程调用 `release()` 方法。，

**主要方法:**

**`init(self, value=1)`**
- 创建一个`Semaphore`实例,参数`value`为数器的初始值
**`acquire()`**
- `acquire()`方法尝试获取一个锁。如果计数器大于0，它会减1并立即返回`True`；如果计数器为0，线程将被阻塞，直到其他线程调用`release()`方法。
`release()`
- `release()`方法将计数器加1，如果计数器为0，它会唤醒一个因调用`acquire()`而阻塞的线程。
**`with`语句**
- 使用`with`语句可以更优雅地管理`Semaphore`的获取和释放，确保即使在发生异常的情况下，资源也会被正确释放。
```python
import threading  
import time  
from threading import Thread, Semaphore  
  
# 创建锁  
countdown = 2  
semaphore = Semaphore(countdown)  # 最多允许3个线程同时访问网络  
  
def worker(i):  
    with semaphore:  
        if i > countdown:  
            print('大于semaphore计数，需要等待，其他10秒后的释放')  
        print('running...')  
        time.sleep(10)  
        pass  
  
t1 = threading.Thread(target=worker,args=(1,))  
t2 = threading.Thread(target=worker,args=(2,))  
t3 = threading.Thread(target=worker,args=(3,))  
t1.start()  
t2.start()  
t3.start()  
t1.join()  
t2.join()  
t3.join()  
print('end')
```
#### BoundedSemaphore（有界信号量）

`threading.BoundedSemaphore`是Python的`threading`模块中提供的一种特殊类型的信号量，它与普通信号量`threading.Semaphore`相似，但具有**额外的边界检查功能**。`BoundedSemaphore`**用于控制同时访问共享资源的线程数量，同时避免信号量的值超过其初始值，这有助于预防因过多的release()调用而导致的错误状态**。

用法与上面的`Semaphore`相同


#### Barrier（屏障）
`threading.Barrier()` 用于让一组线程在到达某个点时互相等待，直到所有线程都到达该点后，所有线程才会继续执行。可以确保一组线程在继续执行前达到一个同步点。

**重要方法**
**`init(parties, action=None, timeout=None)`**：
- `parties`：需要等待的线程数量。
- `action`：可选参数，一个可调用对象，当所有线程到达barrier时，会由一个线程调用此函数。
- `timeout`：可选参数，等待的超时时间，单位是秒。如果超时，到达`barrier`的线程将抛出`BrokenBarrierError`异常。
**`wait(timeout=None)`**：
- 线程调用此方法等待其他线程到达`barrier`。如果`timeout`参数给出并且在超时时间内所有线程未到达`barrier`，则抛出`BrokenBarrierError`异常。
**`abort()`**：
- 强制破坏`barrier`，导致所有等待的线程抛出`BrokenBarrierError`异常。
**`reset()`**：
- 重置`barrier`，丢弃所有等待的线程，这些线程将抛出`BrokenBarrierError`异常。

```python
import threading  
import time  
from threading import Barrier  
  
def worker(barrier, id):  
    print(f"Thread {id} arrived at barrier.")  
    barrier.wait()  # 等待所有线程到达barrier  
    print(f"Thread {id} continuing after barrier.")  
  
barrier = Barrier(2)  
  
t1 = threading.Thread(target=worker, args=(barrier, 1))  
t2 = threading.Thread(target=worker, args=(barrier, 2))  
  
t1.start()  
t2.start()  
  
t1.join()  
t2.join()
```


#### Thread Local（线程局部存储）

`threading.local`是Python的`threading`模块中提供的一种机制，用于**在线程之间隔离数据，使得每个线程都有自己的局部副本**。这对于避免多线程环境中的数据竞争和同步问题非常有用，尤其是在不需要显式锁定的情况下。

```python
import threading

# 创建一个threading.local对象
local_data = threading.local()

def worker():
    local_data.counter = 0  # 每个线程有自己的counter属性
    for _ in range(1000000):
        local_data.counter += 1
    print(f"Thread {threading.current_thread().name}: {local_data.counter}")

# 创建两个线程
threads = [threading.Thread(target=worker) for _ in range(2)]

# 启动线程
for t in threads:
    t.start()

# 等待所有线程完成
for t in threads:
    t.join()
```

#### Event（事件）

`threading.Event()` 是用于线程间简单通信的同步原语。`Event`对象维护了一个内部标志（`flag`），线程可以通过这个标志的状态（`True`或`False`）来决定是否等待或继续执行。`Event`对象主要用于协调多个线程之间的执行流程，比如在一个线程完成某些工作后通知其他线程开始执行。一个线程可以调用` set() `方法来设置事件，而其他线程可以调用 `wait() `方法来等待事件被设置

**`Event` 的重要方法**
`Event` 对象提供了以下几种方法用于控制和查询内部标志的状态：

- `is_set()`：如果内部标志为`True`则返回`True`，否则返回`False`。
- `set()`：将内部标志设置为`True`。所有处于等待状态的线程将被唤醒。
- `clear()`：将内部标志设置为`False`。
- `wait(timeout=None)`：如果内部标志为`True`，线程将继续执行；如果内部标志为`False`，线程将被阻塞，直到满足以下任一条件：
	- 内部标志被`set()`方法设置为`True`。
	- 可选的`timeout`参数指定的时间间隔已过。

```python
import threading
import time

def worker(event):
    print("Worker thread waiting for event...")
    event.wait()  # 等待事件被设置
    print("Worker thread received event, continuing...")

def main():
    event = threading.Event()

    # 创建并启动worker线程
    thread = threading.Thread(target=worker, args=(event,))
    thread.start()

    # 主线程等待一段时间
    time.sleep(2)
    print("Main thread setting event...")
    event.set()  # 设置事件

    thread.join()

if __name__ == "__main__":
    main()
```
\

## Future

`Future`对象代表了一个可能还没有完成的计算的结果。它可以被看作是一个占位符，它最终将持有计算的结果，或者表示计算失败的异常。

**常用操作**

- **异步结果获取**： `Future`对象允许你在稍后的某个时间点获取异步计算的结果。你可以通过调用`result()`方法来获取结果，但请注意，如果计算尚未完成，`result()`方法将阻塞直到计算完成。
- **错误处理**： 如果异步计算过程中发生了异常，`Future`对象将捕获这个异常。你可以通过调用`exception()`方法来检查是否有异常发生，或者通过`add_done_callback()`方法添加一个回调函数，在计算完成时（无论是成功还是失败）执行。
- **任务完成状态**：` Future`对象提供了`done()`方法来检查计算是否已经完成。这在需要知道任务状态时非常有用，例如在等待多个任务完成时。
- **取消任务**： 如果任务还未开始执行，你可以调用`cancel()`方法来取消任务。如果任务已经开始执行，`cancel()`可能不会立即生效，具体取决于底层的执行器。
- 完成的顺序返回：`as_completed`允许你迭代一个`Future`对象的序列，并按完成的顺序返回这些`Future`对象，而不管它们最初提交的顺序如何。
	```python
	for future in concurrent.futures.as_completed(fs, timeout=None):
	    # 处理future
	```

示例：
```python
import concurrent.futures
import time

def long_running_task(n):
    time.sleep(n)
    return n * n

if __name__ == "__main__":
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future = executor.submit(long_running_task, 2)
        print("Scheduled for 2 seconds...")
        time.sleep(1)
        print("1 second passed but the task is not done yet.")
        if future.done():
            print("Task finished in less than 1 second!")
        else:
            print("Still waiting...")
        result = future.result()
        print(f"Task result: {result}")
```


## asyncio

`asyncio`是Python用于编写单线程并发代码的库，它基于协程、事件循环和回调。`asyncio`库使开发人员能够在Python中编写异步IO驱动的服务器和客户端，**非常适合处理I/O密集型任务**，比如网络请求、文件读写等，而不必担心线程之间的同步问题。

**主要概念**

**事件循环（Event Loop）**： 事件循环是`asyncio`的核心组件，它负责调度和执行协程。事件循环监听各种事件，如I/O操作完成或定时器到期，并在这些事件发生时唤醒相应的协程。
**协程（Coroutine）**： 协程是一种特殊的函数，可以暂停和恢复执行。在`asyncio`中，协程通常使用`async def`语法定义，并可以使用`await`关键字等待其他协程或异步操作完成。
**任务（Task）**： 任务是协程的包装器，它们被提交给事件循环进行调度。任务可以被取消，可以附加回调函数，并且可以检查其状态和结果。
**Future**： `Future`是`asyncio`中的一个异步结果封装对象。`Future`对象可以被等待，可以检查是否完成，可以获取结果或异常，还可以被取消

```python
import asyncio

async def worker_coroutine(id):
    print(f"Coroutine {id} started")
    await asyncio.sleep(2)  # 模拟耗时操作
    print(f"Coroutine {id} finished")

async def main():
    tasks = []
    for i in range(5):
        task = asyncio.create_task(worker_coroutine(i))
        tasks.append(task)
    
    await asyncio.gather(*tasks)

# 运行异步任务
asyncio.run(main())
```


**`asyncio`中的其他api应用**

- `asyncio.gather`： `gather`函数可以并发执行多个协程，并**等待它们全部完成**。它会返回一个列表，包含了所有协程的结果，结果的顺序与协程的输入顺序相对应。如果任何一个协程抛出了异常，`gather`会立即终止并抛出这个异常。
- `asyncio.wait`：` wait`函数可以等待多个`Future`或协程完成，但不像`gather`那样等待所有协程完成才返回。它返回两个集合：一个是已完成的Future和协程，另一个是未完成的`Future`和协程。这使得你可以处理已完成的任务，而无需等待所有任务完成。
- `asyncio.as_completed`： as_completed函数允许你迭代一个Future或协程的序列，并按完成的顺序返回这些Future或协程。这与wait不同，后者不保证返回的顺序。

**任务管理**

- `asyncio.create_task`： 这是创建任务的推荐方式，它将协程包装成一个任务，并安排其在事件循环中执行。任务提供了更多的管理功能，如取消、检查状态和获取结果。
- `asyncio.shield`： `shield`函数可以保护一个任务不受取消的影响。如果一个受保护的任务被取消，它将忽略取消请求并继续执行，直到自然完成。这对于需要确保完成的关键任务非常有用。

**异步上下文管理器**

`async with`： 异步上下文管理器允许你使用`async with`语句来管理异步资源，如打开和关闭文件、连接数据库等。这确保了资源在使用后会被正确地清理。

**异步迭代器**

`async for`： 异步迭代器允许你使用`async for`循环来异步地遍历可迭代对象。这在处理大量数据或流数据时非常有用，因为它可以按需加载数据，而不是一次性加载所有数据到内存中。

**高级网络API**

`asyncio.streams`： 提供了流式接口，可以用于创建和管理TCP、UDP等网络连接。
`asyncio.sslproto`： 支持TLS/SSL加密的网络通信。

**异常处理**

`asyncio.exceptions`： 包含了一系列异常类，用于处理异步编程中常见的错误情况，如取消、超时和协议错误。

**调试和监控**
`asyncio.tasks`： 提供了任务的管理，包括任务的取消和监控。
`asyncio.events`： 事件模块可以用于在协程之间发送信号，这对于协调多个协程的执行非常有用。

**时间相关API**
`asyncio.sleep`： 异步睡眠函数，用于暂停协程的执行一定时间，不会阻塞事件循环